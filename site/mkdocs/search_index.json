{
    "docs": [
        {
            "location": "/index.html", 
            "text": "Python For Hackers - Class 3\n\n\nWorkshop overview\n\n\n\n\nThis is an intense workshop on making web-bots and scraping websites.\n\n\nWe'll understand HTML programming and then move on to scraping websites.\n\n\nWe'll leverage selenium module to automate tasks.\n\n\n\n\nConcepts Covered\n\n\n\n\nHTML basics\n\n\nBeautifulSoup\n\n\nSelenium\n\n\n\n\nTechnical prerequisites\n\n\n\n\nLaptop with administrator access (mandatory).\n\n\nMinimum 4 GB RAM and 15 GB free hard disk space (More the better).\n\n\nPreferably running Linux as primary OS but Windows/Mac is permissible.\n\n\nPreferably, your own Internet connectivity.\n\n\n\n\nLibraries/Modules\n\n\n\n\nBeautifulSoup\n\n\nSelenium\n\n\nurllib\n\n\nWebDriver", 
            "title": "Home"
        }, 
        {
            "location": "/index.html#python-for-hackers-class-3", 
            "text": "", 
            "title": "Python For Hackers - Class 3"
        }, 
        {
            "location": "/index.html#workshop-overview", 
            "text": "This is an intense workshop on making web-bots and scraping websites.  We'll understand HTML programming and then move on to scraping websites.  We'll leverage selenium module to automate tasks.", 
            "title": "Workshop overview"
        }, 
        {
            "location": "/index.html#concepts-covered", 
            "text": "HTML basics  BeautifulSoup  Selenium", 
            "title": "Concepts Covered"
        }, 
        {
            "location": "/index.html#technical-prerequisites", 
            "text": "Laptop with administrator access (mandatory).  Minimum 4 GB RAM and 15 GB free hard disk space (More the better).  Preferably running Linux as primary OS but Windows/Mac is permissible.  Preferably, your own Internet connectivity.", 
            "title": "Technical prerequisites"
        }, 
        {
            "location": "/index.html#librariesmodules", 
            "text": "BeautifulSoup  Selenium  urllib  WebDriver", 
            "title": "Libraries/Modules"
        }, 
        {
            "location": "/license/index.html", 
            "text": "", 
            "title": "license"
        }, 
        {
            "location": "/bigger_picture/index.html", 
            "text": "Bigger Picture", 
            "title": "Bigger Picture"
        }, 
        {
            "location": "/bigger_picture/index.html#bigger-picture", 
            "text": "", 
            "title": "Bigger Picture"
        }, 
        {
            "location": "/speakers/index.html", 
            "text": "Speakers\n\n\n\n\n\n\nAditya Kamat\n\n\n\n\n\n\nP Punith Krishna", 
            "title": "Speakers"
        }, 
        {
            "location": "/speakers/index.html#speakers", 
            "text": "", 
            "title": "Speakers"
        }, 
        {
            "location": "/speakers/index.html#aditya-kamat", 
            "text": "", 
            "title": "Aditya Kamat"
        }, 
        {
            "location": "/speakers/index.html#p-punith-krishna", 
            "text": "", 
            "title": "P Punith Krishna"
        }, 
        {
            "location": "/workshop_settings/index.html", 
            "text": "Settings\n\n\nThe Goal\n\n\n\n\nUnderstanding HTML and analyzing websites.\n\n\nScraping static websites hosted on the VM.\n\n\nScraping websites which are implemented using AJAX.\n\n\nUsing selenium to create web-bots to automate certain tasks.\n\n\n\n\nQuestions\n\n\n\n\n~~RTFM~~\n\n\nAsk them when you got them.\n\n\nIt\u2019s easy to get lost so try not to be on auto pilot mode.\n\n\n\n\nWorkshop\n\n\n\n\nMeter wide \n Mile deep!\n\n\nPentesters point of view.\n\n\nMinimal theory, maximal hands-on.\n\n\nProgramming experience in Python preferred but it\u2019s possible to follow even without it.\n\n\nPython 2.7.x\n\n\n\n\nFor more on Python 2.x vs 3.x Python 2.x vs 3.x", 
            "title": "Workshop Settings"
        }, 
        {
            "location": "/workshop_settings/index.html#settings", 
            "text": "", 
            "title": "Settings"
        }, 
        {
            "location": "/workshop_settings/index.html#the-goal", 
            "text": "Understanding HTML and analyzing websites.  Scraping static websites hosted on the VM.  Scraping websites which are implemented using AJAX.  Using selenium to create web-bots to automate certain tasks.", 
            "title": "The Goal"
        }, 
        {
            "location": "/workshop_settings/index.html#questions", 
            "text": "~~RTFM~~  Ask them when you got them.  It\u2019s easy to get lost so try not to be on auto pilot mode.", 
            "title": "Questions"
        }, 
        {
            "location": "/workshop_settings/index.html#workshop", 
            "text": "Meter wide   Mile deep!  Pentesters point of view.  Minimal theory, maximal hands-on.  Programming experience in Python preferred but it\u2019s possible to follow even without it.  Python 2.7.x   For more on Python 2.x vs 3.x Python 2.x vs 3.x", 
            "title": "Workshop"
        }, 
        {
            "location": "/disclaimer/index.html", 
            "text": "Legal ramifications!\n\n\nThe legal ramifications of scanning networks are complex and controversial(like with many other laws pertaining to computer security). When using tools like Scapy/Nmap the line between doing something benign and malignant is thin.\n\n\nWe have mentioned some guidelines to really keep in mind while dealing with this scenario :\n\n\nTerms and Conditions of Use\n \u2013 Some of the websites put efforts to prevent scraping by keeping out it in their online Terms of Service. This is not true for all the cases, as some courts don\u2019t like to impose online terms against users who have not agreed to them.\n\n\nCopyright\n \u2013Some of the courts have agreed that though arrangement, formatting, or an assortment of pure proofsor facts may be copyrighted, the proofs themselves may not be. However, the Court added, although the facts are not endangered, the methods in which they are prearranged may be. In real world terms, this means that simply having a copyright may not guard the content of a web source.\n\n\nOriginal, but useless justifications\n \u2013 As it\u2019s difficult for websites to defend pure facts, lawyers have come up with exclusive arguments of why the data is protected.", 
            "title": "Disclaimer"
        }, 
        {
            "location": "/disclaimer/index.html#legal-ramifications", 
            "text": "The legal ramifications of scanning networks are complex and controversial(like with many other laws pertaining to computer security). When using tools like Scapy/Nmap the line between doing something benign and malignant is thin.  We have mentioned some guidelines to really keep in mind while dealing with this scenario :  Terms and Conditions of Use  \u2013 Some of the websites put efforts to prevent scraping by keeping out it in their online Terms of Service. This is not true for all the cases, as some courts don\u2019t like to impose online terms against users who have not agreed to them.  Copyright  \u2013Some of the courts have agreed that though arrangement, formatting, or an assortment of pure proofsor facts may be copyrighted, the proofs themselves may not be. However, the Court added, although the facts are not endangered, the methods in which they are prearranged may be. In real world terms, this means that simply having a copyright may not guard the content of a web source.  Original, but useless justifications  \u2013 As it\u2019s difficult for websites to defend pure facts, lawyers have come up with exclusive arguments of why the data is protected.", 
            "title": "Legal ramifications!"
        }, 
        {
            "location": "/license/index.html", 
            "text": "", 
            "title": "About"
        }, 
        {
            "location": "/html/index.html", 
            "text": "HTML\n\n\nHTML Documents\n\n\nAll HTML documents must start with a document type declaration: \n!DOCTYPE html\n.\n\n\nThe HTML document itself begins with \n and ends with \n.\n\n\nThe visible part of the HTML document is between \n and \n.\n\n\n Example \n\n\n!DOCTYPE html\n\n  \nhtml\n\n  \nbody\n\n  \nh1\nMy First Heading\n/h1\n\n  \np\nMy first paragraph.\n/p\n\n  \n/body\n\n  \n/html\n\n\n\n\n\nHTML Headings\n\n\nh1\nThis is heading 1\n/h1\n\n\nh2\nThis is heading 2\n/h2\n\n\nh3\nThis is heading 3\n/h3\n\n\n\n\n\nHTML Paragraphs\n\n\np\nThis is a paragraph.\n/p\n\n\np\nThis is another paragraph.\n/p\n\n\n\n\n\nHTML Links\n\n\na href=\nhttps://www.w3schools.com\nThis is a link\n/a\n\n\n\n\n\nHTML Images\n\n\nimg src=\nw3schools.jpg\n alt=\nW3Schools.com\n width=\n104\n height=\n142\n\n\n\n\n\n\nHTML Tables\n\n\nAn HTML table is defined with the \ntable\n tag.\n\n\nEach table row is defined with the \ntr\n tag. A table header is defined with the \nth\n tag. By default, table headings are bold and centered. A table data/cell is defined with the \ntd\n tag.\n\n\nExample\n\n\ntable style=\nwidth:100%\n\n  \ntr\n\n    \nth\nFirstname\n/th\n\n    \nth\nLastname\n/th\n\n    \nth\nAge\n/th\n\n  \n/tr\n\n  \ntr\n\n    \ntd\nJill\n/td\n\n    \ntd\nSmith\n/td\n\n    \ntd\n50\n/td\n\n  \n/tr\n\n  \ntr\n\n    \ntd\nEve\n/td\n\n    \ntd\nJackson\n/td\n\n    \ntd\n94\n/td\n\n  \n/tr\n\n\n/table\n\n\n\n\n\nUnordered HTML List\n\n\nAn unordered list starts with the \nul\n tag. Each list item starts with the \nli\n tag.\n\n\nThe list items will be marked with bullets (small black circles) by default:\n\n\nExample\n\n\nul\n\n  \nli\nCoffee\n/li\n\n  \nli\nTea\n/li\n\n  \nli\nMilk\n/li\n\n\n/ul\n\n\n\n\n\nOrdered HTML List\n\n\nAn ordered list starts with the \nol\n tag. Each list item starts with the \nli\n tag.\n\n\nThe list items will be marked with numbers by default:\n\n\nExample\n\n\nol\n\n  \nli\nCoffee\n/li\n\n  \nli\nTea\n/li\n\n  \nli\nMilk\n/li\n\n\n/ol\n\n\n\n\n\nHTML The class Attribute\n\n\nUsing The class Attribute\n\n\nThe HTML class attribute makes it possible to define equal styles for elements with the same class name.\n\n\nHere we have three \ndiv\n elements that point to the same class name:\n\n\nExample\n\n\n!DOCTYPE html\n\n\nhtml\n\n\nhead\n\n\nstyle\n\nspan.note {\n    font-size: 120%;\n    color: red;\n}\n\n/style\n\n\n/head\n\n\nbody\n\n\n\nh1\nMy \nspan class=\nnote\nImportant\n/span\n Heading\n/h1\n\n\np\nThis is some \nspan class=\nnote\nimportant\n/span\n text.\n/p\n\n\n\n/body\n\n\n/html\n\n\n\n\n\nHTML id Attribute\n\n\nThe id attribute specifies a unique id for an HTML element (the value must be unique within the HTML document).\n\n\nThe id attribute is most used to point to a style in a style sheet, and by JavaScript (via the HTML DOM) to manipulate the element with the specific id.\n\n\nhtml\n\n\nbody\n\n\n\nh1 id=\nmyHeader\nHello World!\n/h1\n\n\nbutton onclick=\ndisplayResult()\nChange text\n/button\n\n\n\nscript\n\nfunction displayResult() {\n    document.getElementById(\nmyHeader\n).innerHTML = \nHave a nice day!\n;\n}\n\n/script\n\n\n\n/body\n\n\n/html\n\n\n\n\n\nsource : https://www.w3schools.com/", 
            "title": "HTML"
        }, 
        {
            "location": "/html/index.html#html", 
            "text": "", 
            "title": "HTML"
        }, 
        {
            "location": "/html/index.html#html-documents", 
            "text": "All HTML documents must start with a document type declaration:  !DOCTYPE html .  The HTML document itself begins with   and ends with  .  The visible part of the HTML document is between   and  .", 
            "title": "HTML Documents"
        }, 
        {
            "location": "/html/index.html#example", 
            "text": "!DOCTYPE html \n   html \n   body \n   h1 My First Heading /h1 \n   p My first paragraph. /p \n   /body \n   /html", 
            "title": "Example"
        }, 
        {
            "location": "/html/index.html#html-headings", 
            "text": "h1 This is heading 1 /h1  h2 This is heading 2 /h2  h3 This is heading 3 /h3", 
            "title": "HTML Headings"
        }, 
        {
            "location": "/html/index.html#html-paragraphs", 
            "text": "p This is a paragraph. /p  p This is another paragraph. /p", 
            "title": "HTML Paragraphs"
        }, 
        {
            "location": "/html/index.html#html-links", 
            "text": "a href= https://www.w3schools.com This is a link /a", 
            "title": "HTML Links"
        }, 
        {
            "location": "/html/index.html#html-images", 
            "text": "img src= w3schools.jpg  alt= W3Schools.com  width= 104  height= 142", 
            "title": "HTML Images"
        }, 
        {
            "location": "/html/index.html#html-tables", 
            "text": "An HTML table is defined with the  table  tag.  Each table row is defined with the  tr  tag. A table header is defined with the  th  tag. By default, table headings are bold and centered. A table data/cell is defined with the  td  tag.", 
            "title": "HTML Tables"
        }, 
        {
            "location": "/html/index.html#example_1", 
            "text": "table style= width:100% \n   tr \n     th Firstname /th \n     th Lastname /th \n     th Age /th \n   /tr \n   tr \n     td Jill /td \n     td Smith /td \n     td 50 /td \n   /tr \n   tr \n     td Eve /td \n     td Jackson /td \n     td 94 /td \n   /tr  /table", 
            "title": "Example"
        }, 
        {
            "location": "/html/index.html#unordered-html-list", 
            "text": "An unordered list starts with the  ul  tag. Each list item starts with the  li  tag.  The list items will be marked with bullets (small black circles) by default:", 
            "title": "Unordered HTML List"
        }, 
        {
            "location": "/html/index.html#example_2", 
            "text": "ul \n   li Coffee /li \n   li Tea /li \n   li Milk /li  /ul", 
            "title": "Example"
        }, 
        {
            "location": "/html/index.html#ordered-html-list", 
            "text": "An ordered list starts with the  ol  tag. Each list item starts with the  li  tag.  The list items will be marked with numbers by default:", 
            "title": "Ordered HTML List"
        }, 
        {
            "location": "/html/index.html#example_3", 
            "text": "ol \n   li Coffee /li \n   li Tea /li \n   li Milk /li  /ol", 
            "title": "Example"
        }, 
        {
            "location": "/html/index.html#html-the-class-attribute", 
            "text": "", 
            "title": "HTML The class Attribute"
        }, 
        {
            "location": "/html/index.html#using-the-class-attribute", 
            "text": "The HTML class attribute makes it possible to define equal styles for elements with the same class name.  Here we have three  div  elements that point to the same class name:", 
            "title": "Using The class Attribute"
        }, 
        {
            "location": "/html/index.html#example_4", 
            "text": "!DOCTYPE html  html  head  style \nspan.note {\n    font-size: 120%;\n    color: red;\n} /style  /head  body  h1 My  span class= note Important /span  Heading /h1  p This is some  span class= note important /span  text. /p  /body  /html", 
            "title": "Example"
        }, 
        {
            "location": "/html/index.html#html-id-attribute", 
            "text": "The id attribute specifies a unique id for an HTML element (the value must be unique within the HTML document).  The id attribute is most used to point to a style in a style sheet, and by JavaScript (via the HTML DOM) to manipulate the element with the specific id.  html  body  h1 id= myHeader Hello World! /h1  button onclick= displayResult() Change text /button  script \nfunction displayResult() {\n    document.getElementById( myHeader ).innerHTML =  Have a nice day! ;\n} /script  /body  /html   source : https://www.w3schools.com/", 
            "title": "HTML id Attribute"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html", 
            "text": "Beautiful Soup Documentation\n\n\nBeautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.\n\n\nThere's a \nHTML document\n, We\u2019ll be using that as an example throughout this session.\n\n\n\n\nhtml\nhead\ntitle\nThe Dormouse's story\n/title\n/head\n\n\nbody\n\n\np class=\ntitle\nb\nThe Dormouse's story\n/b\n/p\n\n\n\np class=\nstory\nOnce upon a time there were three little sisters; and their names were\n\na href=\nhttp://example.com/elsie\n class=\nsister\n id=\nlink1\nElsie\n/a\n,\n\na href=\nhttp://example.com/lacie\n class=\nsister\n id=\nlink2\nLacie\n/a\n and\n\na href=\nhttp://example.com/tillie\n class=\nsister\n id=\nlink3\nTillie\n/a\n;\nand they lived at the bottom of a well.\n/p\n\n\n\np class=\nstory\n...\n/p\n\n\n\n\n\n\n\nRunning the \u201cthree sisters\u201d document through Beautiful Soup gives us a BeautifulSoup object, which represents the document as a nested data structure:\n\n\nfrom BeautifulSoup import *\nsoup = BeautifulSoup(html_doc, 'html.parser')\n\nprint(soup.prettify())\n# \nhtml\n\n#  \nhead\n\n#   \ntitle\n\n#    The Dormouse's story\n#   \n/title\n\n#  \n/head\n\n#  \nbody\n\n#   \np class=\ntitle\n\n#    \nb\n\n#     The Dormouse's story\n#    \n/b\n\n#   \n/p\n\n#   \np class=\nstory\n\n#    Once upon a time there were three little sisters; and their names were\n#    \na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\n\n#     Elsie\n#    \n/a\n\n#    ,\n#    \na class=\nsister\n href=\nhttp://example.com/lacie\n id=\nlink2\n\n#     Lacie\n#    \n/a\n\n#    and\n#    \na class=\nsister\n href=\nhttp://example.com/tillie\n id=\nlink2\n\n#     Tillie\n#    \n/a\n\n#    ; and they lived at the bottom of a well.\n#   \n/p\n\n#   \np class=\nstory\n\n#    ...\n#   \n/p\n\n#  \n/body\n\n# \n/html\n\n\n\n\n\nMaking the soup\n\n\nTo parse a document, pass it into the \nBeautifulSoup\n constructor. You can pass in a \nstring\n or an open \nfilehandle\n:\n\n\nfrom BeautifulSoup import *\n\nwith open(\nindex.html\n) as fp:\n    soup = BeautifulSoup(fp) #1\n\nsoup = BeautifulSoup(\nhtml\ndata\n/html\n) #2\n\n\n\n\nFirst, the document is converted to \nUnicode\n, and HTML entities are converted to Unicode characters:\n\n\nBeautifulSoup(\nSacr\neacute; bleu!\n)\n\nhtml\nhead\n/head\nbody\nSacr\u00e9 bleu!\n/body\n/html\n\n\n\n\n\nBeautiful Soup then parses the document using the best available parser. It will use an HTML parser unless you specifically tell it to use an XML parser.\n\n\nKinds of objects\n\n\nBeautiful Soup transforms a complex HTML document into a complex tree of Python objects. But you\u2019ll only ever have to deal with about four kinds of objects: \nTag\n,\nNavigableString\n, \nBeautifulSoup,\n and \nComment\n.\n\n\nTag\n\n\nA \nTag\n object corresponds to an XML or HTML tag in the original document:\n\n\nsoup = BeautifulSoup('\nb class=\nboldest\nExtremely bold\n/b\n')\ntag = soup.b\ntype(tag)\n\n\n\n\nName\n\n\nEvery tag has a name, accessible as \n.name\n:\n\n\ntag.name\n# u'b'\n\n\n\n\nIf you change a tag\u2019s name, the change will be reflected in any HTML markup generated by Beautiful Soup:\n\n\ntag.name = \nblockquote\n\ntag\n# \nblockquote class=\nboldest\nExtremely bold\n/blockquote\n\n\n\n\n\nAttributes\n\n\nA tag may have any number of attributes. The tag \nb id=\"boldest\"\n has an attribute \u201cid\u201d whose value is \u201cboldest\u201d. You can access a tag\u2019s attributes by treating the tag like a dictionary:\n\n\ntag['id']\n# u'boldest'\n\n\n\n\nYou can access that dictionary directly as \n.attrs\n:\n\n\ntag.attrs\n# {u'id': 'boldest'}\n\n\n\n\nYou can add, remove, and modify a tag\u2019s attributes. Again, this is done by treating the tag as a dictionary:\n\n\ntag['id'] = 'verybold'\ntag['another-attribute'] = 1\ntag\n# \nb another-attribute=\n1\n id=\nverybold\n/b\n\n\ndel tag['id']\ndel tag['another-attribute']\ntag\n# \nb\n/b\n\n\ntag['id']\n# KeyError: 'id'\nprint(tag.get('id'))\n# None\n\n\n\n\nMulti-valued attributes\n\n\nHTML 4 defines a few attributes that can have multiple values. HTML 5 removes a couple of them, but defines a few more. The most common multi-valued attribute is \nclass\n (that is, a tag can have more than one CSS class). Others include \nrel\n, \nrev\n, \naccept-charset\n, \nheaders\n, and \naccesskey\n. Beautiful Soup presents the value(s) of a multi-valued attribute as a list:\n\n\ncss_soup = BeautifulSoup('\np class=\nbody\n/p\n')\ncss_soup.p['class']\n# [\nbody\n]\n\ncss_soup = BeautifulSoup('\np class=\nbody strikeout\n/p\n')\ncss_soup.p['class']\n# [\nbody\n, \nstrikeout\n]\n\n\n\n\nYou can also use \nget_attribute_list\n to get a value that\u2019s always a list, string, whether or not it\u2019s a multi-valued attribute.\n\n\nIf you parse a document as XML, there are no multi-valued attributes:\n\n\nxml_soup = BeautifulSoup('\np class=\nbody strikeout\n/p\n', 'xml')\nxml_soup.p['class']\n# u'body strikeout'\n\n\n\n\nNavigableString\n\n\nA string corresponds to a bit of text within a tag. Beautiful Soup uses the \nNavigableString\n class to contain these bits of text:\n\n\ntag.string\n# u'Extremely bold'\ntype(tag.string)\n# \nclass 'bs4.element.NavigableString'\n\n\n\n\n\nA \nNavigableString\n is just like a Python Unicode string.\n\n\nYou \ncan\u2019t\n edit a string in place, but you can replace one string with another, using \nreplace_with()\n:\n\n\ntag.string.replace_with(\nNo longer bold\n)\ntag\n# \nblockquote\nNo longer bold\n/blockquote\n\n\n\n\n\nNote\n:\nIf you want to use a \nNavigableString\n outside of Beautiful Soup, you should call unicode() on it to turn it into a normal Python Unicode string. If you don\u2019t, your string will carry around a reference to the entire Beautiful Soup parse tree, even when you\u2019re done using Beautiful Soup. This is a big waste of memory.\n\n\nBeautifulSoup\n\n\nThe \nBeautifulSoup\n object itself represents the document as a whole. For most purposes, you can treat it as a Tag object.\n\n\nSince the \nBeautifulSoup\n object doesn\u2019t correspond to an actual HTML or XML tag, it has no name and no attributes. But sometimes it\u2019s useful to look at its \n.name\n, so it\u2019s been given the special \n.name\n \u201c[document]\u201d:\n\n\nsoup.name\n# u'[document]'\n\n\n\n\nComments and other special strings\n\n\nTag\n, \nNavigableString\n, and \nBeautifulSoup\n cover almost everything you\u2019ll see in an HTML or XML file, but there are a few leftover bits. The only one you\u2019ll probably ever need to worry about is the comment:\n\n\nmarkup = \nb\n!--Hey, buddy. Want to buy a used parser?--\n/b\n\nsoup = BeautifulSoup(markup)\ncomment = soup.b.string\ntype(comment)\n# \nclass 'bs4.element.Comment'\n\n\n\n\n\nThe \nComment\n object is just a special type of \nNavigableString\n:", 
            "title": "Beautiful Soup - Intro"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html#beautiful-soup-documentation", 
            "text": "Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.  There's a  HTML document , We\u2019ll be using that as an example throughout this session.   html head title The Dormouse's story /title /head  body  p class= title b The Dormouse's story /b /p  p class= story Once upon a time there were three little sisters; and their names were a href= http://example.com/elsie  class= sister  id= link1 Elsie /a , a href= http://example.com/lacie  class= sister  id= link2 Lacie /a  and a href= http://example.com/tillie  class= sister  id= link3 Tillie /a ;\nand they lived at the bottom of a well. /p  p class= story ... /p    Running the \u201cthree sisters\u201d document through Beautiful Soup gives us a BeautifulSoup object, which represents the document as a nested data structure:  from BeautifulSoup import *\nsoup = BeautifulSoup(html_doc, 'html.parser')\n\nprint(soup.prettify())\n#  html \n#   head \n#    title \n#    The Dormouse's story\n#    /title \n#   /head \n#   body \n#    p class= title \n#     b \n#     The Dormouse's story\n#     /b \n#    /p \n#    p class= story \n#    Once upon a time there were three little sisters; and their names were\n#     a class= sister  href= http://example.com/elsie  id= link1 \n#     Elsie\n#     /a \n#    ,\n#     a class= sister  href= http://example.com/lacie  id= link2 \n#     Lacie\n#     /a \n#    and\n#     a class= sister  href= http://example.com/tillie  id= link2 \n#     Tillie\n#     /a \n#    ; and they lived at the bottom of a well.\n#    /p \n#    p class= story \n#    ...\n#    /p \n#   /body \n#  /html", 
            "title": "Beautiful Soup Documentation"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html#making-the-soup", 
            "text": "To parse a document, pass it into the  BeautifulSoup  constructor. You can pass in a  string  or an open  filehandle :  from BeautifulSoup import *\n\nwith open( index.html ) as fp:\n    soup = BeautifulSoup(fp) #1\n\nsoup = BeautifulSoup( html data /html ) #2  First, the document is converted to  Unicode , and HTML entities are converted to Unicode characters:  BeautifulSoup( Sacr eacute; bleu! ) html head /head body Sacr\u00e9 bleu! /body /html   Beautiful Soup then parses the document using the best available parser. It will use an HTML parser unless you specifically tell it to use an XML parser.", 
            "title": "Making the soup"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html#kinds-of-objects", 
            "text": "Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. But you\u2019ll only ever have to deal with about four kinds of objects:  Tag , NavigableString ,  BeautifulSoup,  and  Comment .", 
            "title": "Kinds of objects"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html#tag", 
            "text": "A  Tag  object corresponds to an XML or HTML tag in the original document:  soup = BeautifulSoup(' b class= boldest Extremely bold /b ')\ntag = soup.b\ntype(tag)", 
            "title": "Tag"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html#name", 
            "text": "Every tag has a name, accessible as  .name :  tag.name\n# u'b'  If you change a tag\u2019s name, the change will be reflected in any HTML markup generated by Beautiful Soup:  tag.name =  blockquote \ntag\n#  blockquote class= boldest Extremely bold /blockquote", 
            "title": "Name"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html#attributes", 
            "text": "A tag may have any number of attributes. The tag  b id=\"boldest\"  has an attribute \u201cid\u201d whose value is \u201cboldest\u201d. You can access a tag\u2019s attributes by treating the tag like a dictionary:  tag['id']\n# u'boldest'  You can access that dictionary directly as  .attrs :  tag.attrs\n# {u'id': 'boldest'}  You can add, remove, and modify a tag\u2019s attributes. Again, this is done by treating the tag as a dictionary:  tag['id'] = 'verybold'\ntag['another-attribute'] = 1\ntag\n#  b another-attribute= 1  id= verybold /b \n\ndel tag['id']\ndel tag['another-attribute']\ntag\n#  b /b \n\ntag['id']\n# KeyError: 'id'\nprint(tag.get('id'))\n# None", 
            "title": "Attributes"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html#multi-valued-attributes", 
            "text": "HTML 4 defines a few attributes that can have multiple values. HTML 5 removes a couple of them, but defines a few more. The most common multi-valued attribute is  class  (that is, a tag can have more than one CSS class). Others include  rel ,  rev ,  accept-charset ,  headers , and  accesskey . Beautiful Soup presents the value(s) of a multi-valued attribute as a list:  css_soup = BeautifulSoup(' p class= body /p ')\ncss_soup.p['class']\n# [ body ]\n\ncss_soup = BeautifulSoup(' p class= body strikeout /p ')\ncss_soup.p['class']\n# [ body ,  strikeout ]  You can also use  get_attribute_list  to get a value that\u2019s always a list, string, whether or not it\u2019s a multi-valued attribute.  If you parse a document as XML, there are no multi-valued attributes:  xml_soup = BeautifulSoup(' p class= body strikeout /p ', 'xml')\nxml_soup.p['class']\n# u'body strikeout'", 
            "title": "Multi-valued attributes"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html#navigablestring", 
            "text": "A string corresponds to a bit of text within a tag. Beautiful Soup uses the  NavigableString  class to contain these bits of text:  tag.string\n# u'Extremely bold'\ntype(tag.string)\n#  class 'bs4.element.NavigableString'   A  NavigableString  is just like a Python Unicode string.  You  can\u2019t  edit a string in place, but you can replace one string with another, using  replace_with() :  tag.string.replace_with( No longer bold )\ntag\n#  blockquote No longer bold /blockquote   Note :\nIf you want to use a  NavigableString  outside of Beautiful Soup, you should call unicode() on it to turn it into a normal Python Unicode string. If you don\u2019t, your string will carry around a reference to the entire Beautiful Soup parse tree, even when you\u2019re done using Beautiful Soup. This is a big waste of memory.", 
            "title": "NavigableString"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html#beautifulsoup", 
            "text": "The  BeautifulSoup  object itself represents the document as a whole. For most purposes, you can treat it as a Tag object.  Since the  BeautifulSoup  object doesn\u2019t correspond to an actual HTML or XML tag, it has no name and no attributes. But sometimes it\u2019s useful to look at its  .name , so it\u2019s been given the special  .name  \u201c[document]\u201d:  soup.name\n# u'[document]'", 
            "title": "BeautifulSoup"
        }, 
        {
            "location": "/beautiful_soup_intro/index.html#comments-and-other-special-strings", 
            "text": "Tag ,  NavigableString , and  BeautifulSoup  cover almost everything you\u2019ll see in an HTML or XML file, but there are a few leftover bits. The only one you\u2019ll probably ever need to worry about is the comment:  markup =  b !--Hey, buddy. Want to buy a used parser?-- /b \nsoup = BeautifulSoup(markup)\ncomment = soup.b.string\ntype(comment)\n#  class 'bs4.element.Comment'   The  Comment  object is just a special type of  NavigableString :", 
            "title": "Comments and other special strings"
        }, 
        {
            "location": "/navigating_the_tree/index.html", 
            "text": "Navigating the tree\n\n\nGoing down\n\n\nTags may contain strings and other tags. These elements are the tag\u2019s children. Beautiful Soup provides a lot of different attributes for navigating and iterating over a tag\u2019s children.\n\n\nNote that Beautiful Soup strings don\u2019t support any of these attributes, because a string can\u2019t have children.\n\n\nNavigating using tag names\n\n\nThe simplest way to navigate the parse tree is to say the name of the tag you want. If you want the \nhead\n tag, just say \nsoup.head\n:\n\n\nsoup.head\n# \nhead\ntitle\nThe Dormouse's story\n/title\n/head\n\n\nsoup.title\n# \ntitle\nThe Dormouse's story\n/title\n\n\n\n\n\nYou can do use this trick again and again to zoom in on a certain part of the parse tree. This code gets the first \nb\n tag beneath the \nbody\n tag:\n\n\nsoup.body.b\n# \nb\nThe Dormouse's story\n/b\n\n\n\n\n\nUsing a tag name as an attribute will give you only the \nfirst\n tag by that name:\n\n\nsoup.a\n# \na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\nElsie\n/a\n\n\n\n\n\n.contents\n and \n.children\n\n\nA tag\u2019s children are available in a list called \n.contents\n:\n\n\nhead_tag = soup.head\nhead_tag\n# \nhead\ntitle\nThe Dormouse's story\n/title\n/head\n\n\nhead_tag.contents\n[\ntitle\nThe Dormouse's story\n/title\n]\n\ntitle_tag = head_tag.contents[0]\ntitle_tag\n# \ntitle\nThe Dormouse's story\n/title\n\ntitle_tag.contents\n# [u'The Dormouse's story']\n\n\n\n\nThe \nBeautifulSoup\n object itself has children. In this case, the \nhtml\n tag is the child of the BeautifulSoup object.:\n\n\nlen(soup.contents)\n# 1\nsoup.contents[0].name\n# u'html'\n\n\n\n\nInstead of getting them as a list, you can iterate over a tag\u2019s children using the \n.children\n generator:\n\n\nfor child in title_tag.children:\n    print(child)\n# The Dormouse's story\n\n\n\n\n.descendants\n\n\nThe \n.contents\n and \n.children\n attributes only consider a tag\u2019s \ndirect\n children. For instance, the \nhead\n tag has a single direct child\u2013the \ntitle\n tag:\n\n\nhead_tag.contents\n# [\ntitle\nThe Dormouse's story\n/title\n]\n\n\n\n\nBut the \ntitle\n tag itself has a child: the string \u201cThe Dormouse\u2019s story\u201d. There\u2019s a sense in which that string is also a child of the \nhead\n tag. The \n.descendants\n attribute lets you iterate over all of a tag\u2019s children, recursively: its direct children, the children of its direct children, and so on:\n\n\nfor child in head_tag.descendants:\n    print(child)\n# \ntitle\nThe Dormouse's story\n/title\n\n# The Dormouse's story\n\n\n\n\nThe \nhead\n tag has only one child, but it has two descendants: the \ntitle\n tag and the \ntitle\n tag\u2019s child. The \nBeautifulSoup\n object only has one direct child (the \nhtml\n tag), but it has a whole lot of descendants:\n\n\nlen(list(soup.children))\n# 1\nlen(list(soup.descendants))\n# 25\n\n\n\n\n.string\n\n\nif a tag has only one child, and that child is a NavigableString, the child is made available as \n.string\n:\n\n\ntitle_tag.string\n# u'The Dormouse's story'\n\n\n\n\nIf a tag\u2019s only child is another tag, and that tag has a \n.string\n, then the parent tag is considered to have the same \n.string\n as its child:\n\n\nhead_tag.contents\n# [\ntitle\nThe Dormouse's story\n/title\n]\n\nhead_tag.string\n# u'The Dormouse's story'\n\n\n\n\nIf a tag contains more than one thing, then it\u2019s not clear what \n.string\n should refer to, so \n.string\n is defined to be \nNone\n:\n\n\nprint(soup.html.string)\n# None\n\n\n\n\n.strings\n and \nstripped_strings\n\n\nIf there\u2019s more than one thing inside a tag, you can still look at just the strings. Use the \n.strings\n generator:\n\n\nfor string in soup.strings:\n    print(repr(string))\n# u\nThe Dormouse's story\n\n# u'\\n\\n'\n# u\nThe Dormouse's story\n\n# u'\\n\\n'\n# u'Once upon a time there were three little sisters; and their names were\\n'\n# u'Elsie'\n# u',\\n'\n# u'Lacie'\n# u' and\\n'\n# u'Tillie'\n# u';\\nand they lived at the bottom of a well.'\n# u'\\n\\n'\n# u'...'\n# u'\\n'\n\n\n\n\nThese strings tend to have a lot of extra whitespace, which you can remove by using the \n.stripped_strings\n generator instead:\n\n\nfor string in soup.stripped_strings:\n    print(repr(string))\n# u\nThe Dormouse's story\n\n# u\nThe Dormouse's story\n\n# u'Once upon a time there were three little sisters; and their names were'\n# u'Elsie'\n# u','\n# u'Lacie'\n# u'and'\n# u'Tillie'\n# u';\\nand they lived at the bottom of a well.'\n# u'...'\n\n\n\n\nHere, strings consisting entirely of whitespace are ignored, and whitespace at the beginning and end of strings is removed.\n\n\nGoing up\n\n\nContinuing the \u201cfamily tree\u201d analogy, every tag and every string has a parent: the tag that contains it.\n\n\n.parent\n\n\n.parents\n\n\nlink = soup.a\nlink\n# \na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\nElsie\n/a\n\nfor parent in link.parents:\n    if parent is None:\n        print(parent)\n    else:\n        print(parent.name)\n# p\n# body\n# html\n# [document]\n# None\n\n\n\n\nGoing sideways\n\n\n.next_sibling\n\n\n.previous_sibling\n\n\nsibling_soup.b.next_sibling\n# \nc\ntext2\n/c\n\n\nsibling_soup.c.previous_sibling\n# \nb\ntext1\n/b", 
            "title": "Navigating The Tree"
        }, 
        {
            "location": "/navigating_the_tree/index.html#navigating-the-tree", 
            "text": "", 
            "title": "Navigating the tree"
        }, 
        {
            "location": "/navigating_the_tree/index.html#going-down", 
            "text": "Tags may contain strings and other tags. These elements are the tag\u2019s children. Beautiful Soup provides a lot of different attributes for navigating and iterating over a tag\u2019s children.  Note that Beautiful Soup strings don\u2019t support any of these attributes, because a string can\u2019t have children.", 
            "title": "Going down"
        }, 
        {
            "location": "/navigating_the_tree/index.html#navigating-using-tag-names", 
            "text": "The simplest way to navigate the parse tree is to say the name of the tag you want. If you want the  head  tag, just say  soup.head :  soup.head\n#  head title The Dormouse's story /title /head \n\nsoup.title\n#  title The Dormouse's story /title   You can do use this trick again and again to zoom in on a certain part of the parse tree. This code gets the first  b  tag beneath the  body  tag:  soup.body.b\n#  b The Dormouse's story /b   Using a tag name as an attribute will give you only the  first  tag by that name:  soup.a\n#  a class= sister  href= http://example.com/elsie  id= link1 Elsie /a", 
            "title": "Navigating using tag names"
        }, 
        {
            "location": "/navigating_the_tree/index.html#contents-and-children", 
            "text": "A tag\u2019s children are available in a list called  .contents :  head_tag = soup.head\nhead_tag\n#  head title The Dormouse's story /title /head \n\nhead_tag.contents\n[ title The Dormouse's story /title ]\n\ntitle_tag = head_tag.contents[0]\ntitle_tag\n#  title The Dormouse's story /title \ntitle_tag.contents\n# [u'The Dormouse's story']  The  BeautifulSoup  object itself has children. In this case, the  html  tag is the child of the BeautifulSoup object.:  len(soup.contents)\n# 1\nsoup.contents[0].name\n# u'html'  Instead of getting them as a list, you can iterate over a tag\u2019s children using the  .children  generator:  for child in title_tag.children:\n    print(child)\n# The Dormouse's story", 
            "title": ".contents and .children"
        }, 
        {
            "location": "/navigating_the_tree/index.html#descendants", 
            "text": "The  .contents  and  .children  attributes only consider a tag\u2019s  direct  children. For instance, the  head  tag has a single direct child\u2013the  title  tag:  head_tag.contents\n# [ title The Dormouse's story /title ]  But the  title  tag itself has a child: the string \u201cThe Dormouse\u2019s story\u201d. There\u2019s a sense in which that string is also a child of the  head  tag. The  .descendants  attribute lets you iterate over all of a tag\u2019s children, recursively: its direct children, the children of its direct children, and so on:  for child in head_tag.descendants:\n    print(child)\n#  title The Dormouse's story /title \n# The Dormouse's story  The  head  tag has only one child, but it has two descendants: the  title  tag and the  title  tag\u2019s child. The  BeautifulSoup  object only has one direct child (the  html  tag), but it has a whole lot of descendants:  len(list(soup.children))\n# 1\nlen(list(soup.descendants))\n# 25", 
            "title": ".descendants"
        }, 
        {
            "location": "/navigating_the_tree/index.html#string", 
            "text": "if a tag has only one child, and that child is a NavigableString, the child is made available as  .string :  title_tag.string\n# u'The Dormouse's story'  If a tag\u2019s only child is another tag, and that tag has a  .string , then the parent tag is considered to have the same  .string  as its child:  head_tag.contents\n# [ title The Dormouse's story /title ]\n\nhead_tag.string\n# u'The Dormouse's story'  If a tag contains more than one thing, then it\u2019s not clear what  .string  should refer to, so  .string  is defined to be  None :  print(soup.html.string)\n# None", 
            "title": ".string"
        }, 
        {
            "location": "/navigating_the_tree/index.html#strings-and-stripped_strings", 
            "text": "If there\u2019s more than one thing inside a tag, you can still look at just the strings. Use the  .strings  generator:  for string in soup.strings:\n    print(repr(string))\n# u The Dormouse's story \n# u'\\n\\n'\n# u The Dormouse's story \n# u'\\n\\n'\n# u'Once upon a time there were three little sisters; and their names were\\n'\n# u'Elsie'\n# u',\\n'\n# u'Lacie'\n# u' and\\n'\n# u'Tillie'\n# u';\\nand they lived at the bottom of a well.'\n# u'\\n\\n'\n# u'...'\n# u'\\n'  These strings tend to have a lot of extra whitespace, which you can remove by using the  .stripped_strings  generator instead:  for string in soup.stripped_strings:\n    print(repr(string))\n# u The Dormouse's story \n# u The Dormouse's story \n# u'Once upon a time there were three little sisters; and their names were'\n# u'Elsie'\n# u','\n# u'Lacie'\n# u'and'\n# u'Tillie'\n# u';\\nand they lived at the bottom of a well.'\n# u'...'  Here, strings consisting entirely of whitespace are ignored, and whitespace at the beginning and end of strings is removed.", 
            "title": ".strings and stripped_strings"
        }, 
        {
            "location": "/navigating_the_tree/index.html#going-up", 
            "text": "Continuing the \u201cfamily tree\u201d analogy, every tag and every string has a parent: the tag that contains it.  .parent  .parents  link = soup.a\nlink\n#  a class= sister  href= http://example.com/elsie  id= link1 Elsie /a \nfor parent in link.parents:\n    if parent is None:\n        print(parent)\n    else:\n        print(parent.name)\n# p\n# body\n# html\n# [document]\n# None", 
            "title": "Going up"
        }, 
        {
            "location": "/navigating_the_tree/index.html#going-sideways", 
            "text": ".next_sibling  .previous_sibling  sibling_soup.b.next_sibling\n#  c text2 /c \n\nsibling_soup.c.previous_sibling\n#  b text1 /b", 
            "title": "Going sideways"
        }, 
        {
            "location": "/searching_the_tree/index.html", 
            "text": "Searching The Tree\n\n\nBeautiful Soup defines a lot of methods for searching the parse tree, but they\u2019re all very similar. I\u2019m going to spend a lot of time explaining the two most popular methods: find() and find_all().\n\n\nKinds of filters\n\n\nWe can use these filters to filter based on a \ntag\n\u2019s name, on its \nattributes\n, on the \ntext\n of a string, or on some \ncombination\n of these.\n\n\nA string\n\n\nThe simplest filter is a string. Pass a string to a search method and Beautiful Soup will perform a match against that exact string. This code finds all the \nb\n tags in the document:\n\n\nsoup.find_all('b')\n# [\nb\nThe Dormouse's story\n/b\n]\n\n\n\n\nNote\n:If you pass in a byte string, Beautiful Soup will assume the string is encoded as UTF-8. You can avoid this by passing in a Unicode string instead.\n\n\nA regular expression\n\n\nIf you pass in a regular expression object, Beautiful Soup will filter against that regular expression using its \nsearch()\n method. This code finds all the tags whose names start with the letter \u201cb\u201d; in this case, the \nbody\n tag and the \nb\n tag:\n\n\nimport re\nfor tag in soup.find_all(re.compile(\n^b\n)):\n    print(tag.name)\n# body\n# b\n\n\n\n\nThis code finds all the tags whose names contain the letter \u2018t\u2019:\n\n\nfor tag in soup.find_all(re.compile(\nt\n)):\n    print(tag.name)\n# html\n# title\n\n\n\n\nA list\n\n\nIf you pass in a list, Beautiful Soup will allow a string match against any item in that list. This code finds all the \na\n tags and all the \nb\n tags:\n\n\nsoup.find_all([\na\n, \nb\n])\n# [\nb\nThe Dormouse's story\n/b\n,\n#  \na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\nElsie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/lacie\n id=\nlink2\nLacie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/tillie\n id=\nlink3\nTillie\n/a\n]\n\n\n\n\nTrue\n\n\nThe value \nTrue\n matches everything it can. This code finds all the tags in the document, but none of the text strings:\n\n\nfor tag in soup.find_all(True):\n    print(tag.name)\n# html\n# head\n# title\n# body\n# p\n# b\n# p\n# a\n# a\n# a\n# p\n\n\n\n\nA function\n\n\nIf none of the other matches work for you, define a function that takes an element as its only argument. The function should return \nTrue\n if the argument matches, and \nFalse\n otherwise.\nHere\u2019s a function that returns \nTrue\n if a tag defines the \u201cclass\u201d attribute but doesn\u2019t define the \u201cid\u201d attribute:\n\n\ndef has_class_but_no_id(tag):\n    return tag.has_attr('class') and not tag.has_attr('id')\n\n\n\n\nOn passing this function into find_all() and we\u2019ll pick up all the \n tags:\n\n\nsoup.find_all(has_class_but_no_id)\n# [\np class=\ntitle\nb\nThe Dormouse's story\n/b\n/p\n,\n#  \np class=\nstory\nOnce upon a time there were...\n/p\n,\n#  \np class=\nstory\n...\n/p\n]\n\n\n\n\nThis function only picks up the \np\n tags. It doesn\u2019t pick up the \na\n tags, because those tags define both \u201cclass\u201d and \u201cid\u201d. It doesn\u2019t pick up tags like \nhtml\n and \ntitle\n, because those tags don\u2019t define \u201cclass\u201d.\n\n\nfind_all()\n\n\nThe \nfind_all()\n method looks through a tag\u2019s descendants and retrieves all descendants that match your filters.\n\n\nsoup.find_all(\ntitle\n)\n# [\ntitle\nThe Dormouse's story\n/title\n]\n\nsoup.find_all(\np\n, \ntitle\n)\n# [\np class=\ntitle\nb\nThe Dormouse's story\n/b\n/p\n]\n\nsoup.find_all(\na\n)\n# [\na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\nElsie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/lacie\n id=\nlink2\nLacie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/tillie\n id=\nlink3\nTillie\n/a\n]\n\nsoup.find_all(id=\nlink2\n)\n# [\na class=\nsister\n href=\nhttp://example.com/lacie\n id=\nlink2\nLacie\n/a\n]\n\nimport re\nsoup.find(string=re.compile(\nsisters\n))\n# u'Once upon a time there were three little sisters; and their names were\\n'\n\n\n\n\nThe \nname\n argument\n\n\nPass in a value for \nname\nand you\u2019ll tell Beautiful Soup to only consider tags with certain names. Text strings will be ignored, as will tags whose names that don\u2019t match.\n\n\nThis is the simplest usage:\n\n\nsoup.find_all(\ntitle\n)\n# [\ntitle\nThe Dormouse's story\n/title\n]\n\n\n\n\nThe keyword arguments\n\n\nAny argument that\u2019s not recognized will be turned into a filter on one of a tag\u2019s attributes. If you pass in a value for an argument called \nid\n, Beautiful Soup will filter against each tag\u2019s \u2018id\u2019 attribute:\n\n\nsoup.find_all(id='link2')\n# [\na class=\nsister\n href=\nhttp://example.com/lacie\n id=\nlink2\nLacie\n/a\n]\n\n\n\n\nIf you pass in a value for \nhref\n, Beautiful Soup will filter against each tag\u2019s \u2018href\u2019 attribute:\n\n\nsoup.find_all(href=re.compile(\nelsie\n))\n# [\na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\nElsie\n/a\n]\n\n\n\n\nThis code finds all tags whose \nid\n attribute has a value, regardless of what the value is:\n\n\nsoup.find_all(id=True)\n# [\na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\nElsie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/lacie\n id=\nlink2\nLacie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/tillie\n id=\nlink3\nTillie\n/a\n]\n\n\n\n\nYou can filter multiple attributes at once by passing in more than one keyword argument:\n\n\nsoup.find_all(href=re.compile(\nelsie\n), id='link1')\n# [\na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\nthree\n/a\n]\n\n\n\n\nSearching by CSS class\n\n\nIt\u2019s very useful to search for a tag that has a certain CSS class, but the name of the CSS attribute, \u201cclass\u201d, is a reserved word in Python.\n\n\nsoup.find_all(\na\n, class=\nsister\n)\n# [\na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\nElsie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/lacie\n id=\nlink2\nLacie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/tillie\n id=\nlink3\nTillie\n/a\n]\n\n\n\n\nAs with any keyword argument, you can pass \nclass\n a string, a regular expression, a function, or \nTrue\n:\n\n\nsoup.find_all(class_=re.compile(\nitl\n))\n# [\np class=\ntitle\nb\nThe Dormouse's story\n/b\n/p\n]\n\ndef has_six_characters(css_class):\n    return css_class is not None and len(css_class) == 6\n\nsoup.find_all(class_=has_six_characters)\n# [\na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\nElsie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/lacie\n id=\nlink2\nLacie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/tillie\n id=\nlink3\nTillie\n/a\n]\n\n\n\n\nThe \nstring\n argument\n\n\nWith string you can search for strings instead of tags. As with name and the keyword arguments, you can pass in a string, a regular expression, a list, a function, or the value True. Here are some examples:\n\n\nsoup.find_all(string=\nElsie\n)\n# [u'Elsie']\n\nsoup.find_all(string=[\nTillie\n, \nElsie\n, \nLacie\n])\n# [u'Elsie', u'Lacie', u'Tillie']\n\nsoup.find_all(string=re.compile(\nDormouse\n))\n[u\nThe Dormouse's story\n, u\nThe Dormouse's story\n]\n\ndef is_the_only_string_within_a_tag(s):\n    \nReturn True if this string is the only child of its parent tag.\n\n    return (s == s.parent.string)\n\nsoup.find_all(string=is_the_only_string_within_a_tag)\n# [u\nThe Dormouse's story\n, u\nThe Dormouse's story\n, u'Elsie', u'Lacie', u'Tillie', u'...']\n\n\n\n\nAlthough string is for finding strings, you can combine it with arguments that find tags: Beautiful Soup will find all tags whose .string matches your value for string. This code finds the \na\n tags whose .string is \u201cElsie\u201d:\n\n\nsoup.find_all(\na\n, string=\nElsie\n)\n# [\na href=\nhttp://example.com/elsie\n class=\nsister\n id=\nlink1\nElsie\n/a\n]\n\n\n\n\nThe \nlimit\n argument\n\n\nfind_all()\n returns all the tags and strings that match your filters. This can take a while if the document is large. If you don\u2019t need all the results, you can pass in a number for limit. This works just like the LIMIT keyword in SQL. It tells Beautiful Soup to stop gathering results after it\u2019s found a certain number.\n\n\nThere are three links in the \u201cthree sisters\u201d document, but this code only finds the first two:\n\n\nsoup.find_all(\na\n, limit=2)\n# [\na class=\nsister\n href=\nhttp://example.com/elsie\n id=\nlink1\nElsie\n/a\n,\n#  \na class=\nsister\n href=\nhttp://example.com/lacie\n id=\nlink2\nLacie\n/a\n]\n\n\n\n\nfind()\n\n\nSignature: find(name, attrs, recursive, string, \n**kwargs\n)\n\n\nThe \nfind_all()\n method scans the entire document looking for results, but sometimes you only want to find one result. If you know a document only has one \nbody\n tag, it\u2019s a waste of time to scan the entire document looking for more. Rather than passing in \nlimit=1\n every time you call \nfind_all\n, you can use the \nfind()\n method. These two lines of code are nearly equivalent:\n\n\nsoup.find_all('title', limit=1)\n# [\ntitle\nThe Dormouse's story\n/title\n]\n\nsoup.find('title')\n# \ntitle\nThe Dormouse's story\n/title\n\n\n\n\n\nThe only difference is that \nfind_all()\n returns a list containing the single result, and \nfind()\n just returns the result.\n\n\nIf \nfind_all()\n can\u2019t find anything, it returns an empty list. If \nfind()\n can\u2019t find anything, it returns \nNone\n:\n\n\nprint(soup.find(\nnosuchtag\n))\n# None", 
            "title": "Searching The Tree"
        }, 
        {
            "location": "/searching_the_tree/index.html#searching-the-tree", 
            "text": "Beautiful Soup defines a lot of methods for searching the parse tree, but they\u2019re all very similar. I\u2019m going to spend a lot of time explaining the two most popular methods: find() and find_all().", 
            "title": "Searching The Tree"
        }, 
        {
            "location": "/searching_the_tree/index.html#kinds-of-filters", 
            "text": "We can use these filters to filter based on a  tag \u2019s name, on its  attributes , on the  text  of a string, or on some  combination  of these.", 
            "title": "Kinds of filters"
        }, 
        {
            "location": "/searching_the_tree/index.html#a-string", 
            "text": "The simplest filter is a string. Pass a string to a search method and Beautiful Soup will perform a match against that exact string. This code finds all the  b  tags in the document:  soup.find_all('b')\n# [ b The Dormouse's story /b ]  Note :If you pass in a byte string, Beautiful Soup will assume the string is encoded as UTF-8. You can avoid this by passing in a Unicode string instead.", 
            "title": "A string"
        }, 
        {
            "location": "/searching_the_tree/index.html#a-regular-expression", 
            "text": "If you pass in a regular expression object, Beautiful Soup will filter against that regular expression using its  search()  method. This code finds all the tags whose names start with the letter \u201cb\u201d; in this case, the  body  tag and the  b  tag:  import re\nfor tag in soup.find_all(re.compile( ^b )):\n    print(tag.name)\n# body\n# b  This code finds all the tags whose names contain the letter \u2018t\u2019:  for tag in soup.find_all(re.compile( t )):\n    print(tag.name)\n# html\n# title", 
            "title": "A regular expression"
        }, 
        {
            "location": "/searching_the_tree/index.html#a-list", 
            "text": "If you pass in a list, Beautiful Soup will allow a string match against any item in that list. This code finds all the  a  tags and all the  b  tags:  soup.find_all([ a ,  b ])\n# [ b The Dormouse's story /b ,\n#   a class= sister  href= http://example.com/elsie  id= link1 Elsie /a ,\n#   a class= sister  href= http://example.com/lacie  id= link2 Lacie /a ,\n#   a class= sister  href= http://example.com/tillie  id= link3 Tillie /a ]", 
            "title": "A list"
        }, 
        {
            "location": "/searching_the_tree/index.html#true", 
            "text": "The value  True  matches everything it can. This code finds all the tags in the document, but none of the text strings:  for tag in soup.find_all(True):\n    print(tag.name)\n# html\n# head\n# title\n# body\n# p\n# b\n# p\n# a\n# a\n# a\n# p", 
            "title": "True"
        }, 
        {
            "location": "/searching_the_tree/index.html#a-function", 
            "text": "If none of the other matches work for you, define a function that takes an element as its only argument. The function should return  True  if the argument matches, and  False  otherwise.\nHere\u2019s a function that returns  True  if a tag defines the \u201cclass\u201d attribute but doesn\u2019t define the \u201cid\u201d attribute:  def has_class_but_no_id(tag):\n    return tag.has_attr('class') and not tag.has_attr('id')  On passing this function into find_all() and we\u2019ll pick up all the   tags:  soup.find_all(has_class_but_no_id)\n# [ p class= title b The Dormouse's story /b /p ,\n#   p class= story Once upon a time there were... /p ,\n#   p class= story ... /p ]  This function only picks up the  p  tags. It doesn\u2019t pick up the  a  tags, because those tags define both \u201cclass\u201d and \u201cid\u201d. It doesn\u2019t pick up tags like  html  and  title , because those tags don\u2019t define \u201cclass\u201d.", 
            "title": "A function"
        }, 
        {
            "location": "/searching_the_tree/index.html#find_all", 
            "text": "The  find_all()  method looks through a tag\u2019s descendants and retrieves all descendants that match your filters.  soup.find_all( title )\n# [ title The Dormouse's story /title ]\n\nsoup.find_all( p ,  title )\n# [ p class= title b The Dormouse's story /b /p ]\n\nsoup.find_all( a )\n# [ a class= sister  href= http://example.com/elsie  id= link1 Elsie /a ,\n#   a class= sister  href= http://example.com/lacie  id= link2 Lacie /a ,\n#   a class= sister  href= http://example.com/tillie  id= link3 Tillie /a ]\n\nsoup.find_all(id= link2 )\n# [ a class= sister  href= http://example.com/lacie  id= link2 Lacie /a ]\n\nimport re\nsoup.find(string=re.compile( sisters ))\n# u'Once upon a time there were three little sisters; and their names were\\n'", 
            "title": "find_all()"
        }, 
        {
            "location": "/searching_the_tree/index.html#the-name-argument", 
            "text": "Pass in a value for  name and you\u2019ll tell Beautiful Soup to only consider tags with certain names. Text strings will be ignored, as will tags whose names that don\u2019t match.  This is the simplest usage:  soup.find_all( title )\n# [ title The Dormouse's story /title ]", 
            "title": "The name argument"
        }, 
        {
            "location": "/searching_the_tree/index.html#the-keyword-arguments", 
            "text": "Any argument that\u2019s not recognized will be turned into a filter on one of a tag\u2019s attributes. If you pass in a value for an argument called  id , Beautiful Soup will filter against each tag\u2019s \u2018id\u2019 attribute:  soup.find_all(id='link2')\n# [ a class= sister  href= http://example.com/lacie  id= link2 Lacie /a ]  If you pass in a value for  href , Beautiful Soup will filter against each tag\u2019s \u2018href\u2019 attribute:  soup.find_all(href=re.compile( elsie ))\n# [ a class= sister  href= http://example.com/elsie  id= link1 Elsie /a ]  This code finds all tags whose  id  attribute has a value, regardless of what the value is:  soup.find_all(id=True)\n# [ a class= sister  href= http://example.com/elsie  id= link1 Elsie /a ,\n#   a class= sister  href= http://example.com/lacie  id= link2 Lacie /a ,\n#   a class= sister  href= http://example.com/tillie  id= link3 Tillie /a ]  You can filter multiple attributes at once by passing in more than one keyword argument:  soup.find_all(href=re.compile( elsie ), id='link1')\n# [ a class= sister  href= http://example.com/elsie  id= link1 three /a ]", 
            "title": "The keyword arguments"
        }, 
        {
            "location": "/searching_the_tree/index.html#searching-by-css-class", 
            "text": "It\u2019s very useful to search for a tag that has a certain CSS class, but the name of the CSS attribute, \u201cclass\u201d, is a reserved word in Python.  soup.find_all( a , class= sister )\n# [ a class= sister  href= http://example.com/elsie  id= link1 Elsie /a ,\n#   a class= sister  href= http://example.com/lacie  id= link2 Lacie /a ,\n#   a class= sister  href= http://example.com/tillie  id= link3 Tillie /a ]  As with any keyword argument, you can pass  class  a string, a regular expression, a function, or  True :  soup.find_all(class_=re.compile( itl ))\n# [ p class= title b The Dormouse's story /b /p ]\n\ndef has_six_characters(css_class):\n    return css_class is not None and len(css_class) == 6\n\nsoup.find_all(class_=has_six_characters)\n# [ a class= sister  href= http://example.com/elsie  id= link1 Elsie /a ,\n#   a class= sister  href= http://example.com/lacie  id= link2 Lacie /a ,\n#   a class= sister  href= http://example.com/tillie  id= link3 Tillie /a ]", 
            "title": "Searching by CSS class"
        }, 
        {
            "location": "/searching_the_tree/index.html#the-string-argument", 
            "text": "With string you can search for strings instead of tags. As with name and the keyword arguments, you can pass in a string, a regular expression, a list, a function, or the value True. Here are some examples:  soup.find_all(string= Elsie )\n# [u'Elsie']\n\nsoup.find_all(string=[ Tillie ,  Elsie ,  Lacie ])\n# [u'Elsie', u'Lacie', u'Tillie']\n\nsoup.find_all(string=re.compile( Dormouse ))\n[u The Dormouse's story , u The Dormouse's story ]\n\ndef is_the_only_string_within_a_tag(s):\n     Return True if this string is the only child of its parent tag. \n    return (s == s.parent.string)\n\nsoup.find_all(string=is_the_only_string_within_a_tag)\n# [u The Dormouse's story , u The Dormouse's story , u'Elsie', u'Lacie', u'Tillie', u'...']  Although string is for finding strings, you can combine it with arguments that find tags: Beautiful Soup will find all tags whose .string matches your value for string. This code finds the  a  tags whose .string is \u201cElsie\u201d:  soup.find_all( a , string= Elsie )\n# [ a href= http://example.com/elsie  class= sister  id= link1 Elsie /a ]", 
            "title": "The string argument"
        }, 
        {
            "location": "/searching_the_tree/index.html#the-limit-argument", 
            "text": "find_all()  returns all the tags and strings that match your filters. This can take a while if the document is large. If you don\u2019t need all the results, you can pass in a number for limit. This works just like the LIMIT keyword in SQL. It tells Beautiful Soup to stop gathering results after it\u2019s found a certain number.  There are three links in the \u201cthree sisters\u201d document, but this code only finds the first two:  soup.find_all( a , limit=2)\n# [ a class= sister  href= http://example.com/elsie  id= link1 Elsie /a ,\n#   a class= sister  href= http://example.com/lacie  id= link2 Lacie /a ]", 
            "title": "The limit argument"
        }, 
        {
            "location": "/searching_the_tree/index.html#find", 
            "text": "Signature: find(name, attrs, recursive, string,  **kwargs )  The  find_all()  method scans the entire document looking for results, but sometimes you only want to find one result. If you know a document only has one  body  tag, it\u2019s a waste of time to scan the entire document looking for more. Rather than passing in  limit=1  every time you call  find_all , you can use the  find()  method. These two lines of code are nearly equivalent:  soup.find_all('title', limit=1)\n# [ title The Dormouse's story /title ]\n\nsoup.find('title')\n#  title The Dormouse's story /title   The only difference is that  find_all()  returns a list containing the single result, and  find()  just returns the result.  If  find_all()  can\u2019t find anything, it returns an empty list. If  find()  can\u2019t find anything, it returns  None :  print(soup.find( nosuchtag ))\n# None", 
            "title": "find()"
        }, 
        {
            "location": "/getting_started/index.html", 
            "text": "Getting Started\n\n\nSimple Usage\n\n\nWe'll start using Selenium from Python like this.\n\n\nExample\n:\n\n\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\n\ndriver = webdriver.Firefox()\ndriver.get(\nhttp://www.python.org\n)\nassert \nPython\n in driver.title\nelem = driver.find_element_by_name(\nq\n)\nelem.clear()\nelem.send_keys(\npycon\n)\nelem.send_keys(Keys.RETURN)\nassert \nNo results found.\n not in driver.page_source\ndriver.close()\n\n\n\n\nThe above script can be saved into a file (eg:- python_org_search.py), then it can be run like this:\n\n\npython python_org_search.py\n\n\n\n\nExample Explained\n\n\nThe selenium.webdriver module provides all the WebDriver implementations. Currently supported WebDriver implementations are Firefox, Chrome, IE and Remote. The Keys class provide keys in the keyboard like RETURN, F1, ALT etc.\n\n\nfrom selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\n\n\n\n\nNext, the instance of Firefox WebDriver is created.\n\n\ndriver = webdriver.Firefox()\n\n\n\n\nThe driver.get method will navigate to a page given by the URL. WebDriver will wait until the page has fully loaded (that is, the \u201conload\u201d event has fired) before returning control to your test or script. It\u2019s worth noting that if your page uses a lot of AJAX on load then WebDriver may not know when it has completely loaded.:\n\n\ndriver.get(\nhttp://www.python.org\n)\n\n\n\n\nThe next line is an assertion to confirm that title has \u201cPython\u201d word in it:\n\n\nassert \nPython\n in driver.title\n\n\n\n\nWebDriver offers a number of ways to find elements using one of the find_element_by_* methods. For example, the input text element can be located by its name attribute using find_element_by_name method.\n\n\nelem = driver.find_element_by_name(\nq\n)\n\n\n\n\nNext, we are sending keys, this is similar to entering keys using your keyboard. Special keys can be sent using \nKeys\n class imported from \nselenium.webdriver.common.keys\n. To be safe, we\u2019ll first clear any pre-populated text in the input field (e.g. \u201cSearch\u201d) so it doesn\u2019t affect our search results:\n\n\nelem.clear()\nelem.send_keys(\npycon\n)\nelem.send_keys(Keys.RETURN)\n\n\n\n\nAfter submission of the page, you should get the result if there is any. To ensure that some results are found, make an assertion:\n\n\nassert \nNo results found.\n not in driver.page_source\n\n\n\n\nFinally, the browser window is closed. You can also call quit method instead of close. The quit will exit entire browser whereas close will close one tab, but if just one tab was open, by default most browser will exit entirely.:\n\n\ndriver.close()", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting_started/index.html#getting-started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting_started/index.html#simple-usage", 
            "text": "We'll start using Selenium from Python like this.  Example :  from selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys\n\ndriver = webdriver.Firefox()\ndriver.get( http://www.python.org )\nassert  Python  in driver.title\nelem = driver.find_element_by_name( q )\nelem.clear()\nelem.send_keys( pycon )\nelem.send_keys(Keys.RETURN)\nassert  No results found.  not in driver.page_source\ndriver.close()  The above script can be saved into a file (eg:- python_org_search.py), then it can be run like this:  python python_org_search.py", 
            "title": "Simple Usage"
        }, 
        {
            "location": "/getting_started/index.html#example-explained", 
            "text": "The selenium.webdriver module provides all the WebDriver implementations. Currently supported WebDriver implementations are Firefox, Chrome, IE and Remote. The Keys class provide keys in the keyboard like RETURN, F1, ALT etc.  from selenium import webdriver\nfrom selenium.webdriver.common.keys import Keys  Next, the instance of Firefox WebDriver is created.  driver = webdriver.Firefox()  The driver.get method will navigate to a page given by the URL. WebDriver will wait until the page has fully loaded (that is, the \u201conload\u201d event has fired) before returning control to your test or script. It\u2019s worth noting that if your page uses a lot of AJAX on load then WebDriver may not know when it has completely loaded.:  driver.get( http://www.python.org )  The next line is an assertion to confirm that title has \u201cPython\u201d word in it:  assert  Python  in driver.title  WebDriver offers a number of ways to find elements using one of the find_element_by_* methods. For example, the input text element can be located by its name attribute using find_element_by_name method.  elem = driver.find_element_by_name( q )  Next, we are sending keys, this is similar to entering keys using your keyboard. Special keys can be sent using  Keys  class imported from  selenium.webdriver.common.keys . To be safe, we\u2019ll first clear any pre-populated text in the input field (e.g. \u201cSearch\u201d) so it doesn\u2019t affect our search results:  elem.clear()\nelem.send_keys( pycon )\nelem.send_keys(Keys.RETURN)  After submission of the page, you should get the result if there is any. To ensure that some results are found, make an assertion:  assert  No results found.  not in driver.page_source  Finally, the browser window is closed. You can also call quit method instead of close. The quit will exit entire browser whereas close will close one tab, but if just one tab was open, by default most browser will exit entirely.:  driver.close()", 
            "title": "Example Explained"
        }, 
        {
            "location": "/navigating/index.html", 
            "text": "Navigating\n\n\nThe first thing you\u2019ll want to do with WebDriver is navigate to a link. The normal way to do this is by calling \nget\n method:\n\n\ndriver.get(\nhttp://www.google.com\n)\n\n\n\n\nNote\n :\nWebDriver will wait until the page has fully loaded (that is, the onload event has fired) before returning control to your test or script. It\u2019s worth noting that if your page uses a lot of AJAX on load then WebDriver may not know when it has completely loaded. If you need to ensure such pages are fully loaded then you can use waits.\n\n\nInteracting with the page\n\n\nJust being able to go to places isn\u2019t terribly useful. What we\u2019d really like to do is to interact with the pages, or, more specifically, the HTML elements within a page. First of all, we need to find one. WebDriver offers a number of ways to find elements. For example, given an element defined as:\n\n\ninput type=\ntext\n name=\npasswd\n id=\npasswd-id\n /\n\n\n\n\n\nyou could find it using any of:\n\n\nelement = driver.find_element_by_id(\npasswd-id\n)\nelement = driver.find_element_by_name(\npasswd\n)\nelement = driver.find_element_by_xpath(\n//input[@id='passwd-id']\n)\n\n\n\n\nYou can also look for a link by its text, but be careful! The text must be an exact match! You should also be careful when using XPATH in WebDriver. If there\u2019s more than one element that matches the query, then only the first will be returned. If nothing can be found, a \nNoSuchElementException\n will be raised.\n\n\nNow,  you\u2019ve got an element. What can you do with it? First of all, you may want to enter some text into a text field:\n\n\nelement.send_keys(\nsome text\n)\n\n\n\n\nYou can simulate pressing the arrow keys by using the \u201cKeys\u201d class:\n\n\nelement.send_keys(\n and some\n, Keys.ARROW_DOWN)\n\n\n\n\nIt is possible to call send_keys on any element, which makes it possible to test keyboard shortcuts such as those used on GMail. A side-effect of this is that typing something into a text field won\u2019t automatically clear it. Instead, what you type will be appended to what\u2019s already there. You can easily clear the contents of a text field or textarea with the clear method:\n\n\nelement.clear()\n\n\n\n\nDrag and drop\n\n\nYou can use drag and drop, either moving an element by a certain amount, or on to another element:\n\n\nelement = driver.find_element_by_name(\nsource\n)\ntarget = driver.find_element_by_name(\ntarget\n)\n\nfrom selenium.webdriver import ActionChains\naction_chains = ActionChains(driver)\naction_chains.drag_and_drop(element, target).perform()\n\n\n\n\nMoving between windows and frames\n\n\nIt\u2019s rare for a modern web application not to have any frames or to be constrained to a single window. WebDriver supports moving between named windows using the \u201c\nswitch_to_window\n\u201d method:\n\n\ndriver.switch_to_window(\nwindowName\n)\n\n\n\n\nAll calls to \ndriver\n will now be interpreted as being directed to the particular window. But how do you know the window\u2019s name? Take a look at the javascript or link that opened it:\n\n\na href=\nsomewhere.html\n target=\nwindowName\nClick here to open a new window\n/a\n\n\n\n\n\nAlternatively, you can pass a \u201cwindow handle\u201d to the \u201cswitch_to_window()\u201d method. Knowing this, it\u2019s possible to iterate over every open window like so:\n\n\nfor handle in driver.window_handles:\n    driver.switch_to_window(handle)\n\n\n\n\nYou can also swing from frame to frame (or into iframes):\n\n\ndriver.switch_to_frame(\nframeName\n)\n\n\n\n\nOnce we are done with working on frames, we will have to come back to the parent frame which can be done using:\n\n\ndriver.switch_to_default_content()\n\n\n\n\nPopup dialogs\n\n\nSelenium WebDriver has built-in support for handling popup dialog boxes. After you\u2019ve triggered action that would open a popup, you can access the alert with the following:\n\n\nalert = driver.switch_to_alert()\n\n\n\n\nThis will return the currently open alert object. With this object, you can now accept, dismiss, read its contents or even type into a prompt. This interface works equally well on alerts, confirms, prompts. Refer to the API documentation for more information.\n\n\nNavigation: history and location\n\n\nEarlier, we covered navigating to a page using the \u201cget\u201d command ( \ndriver.get(\"http://www.example.com\")\n) As you\u2019ve seen, WebDriver has a number of smaller, task-focused interfaces, and navigation is a useful task. To navigate to a page, you can use get method:\n\n\ndriver.get(\nhttp://www.example.com\n)\n\n\n\n\nTo move backward and forward in your browser\u2019s history:\n\n\ndriver.forward()\ndriver.back()\n\n\n\n\nPlease be aware that this functionality depends entirely on the underlying driver. It\u2019s just possible that something unexpected may happen when you call these methods if you\u2019re used to the behavior of one browser over another.\n\n\nCookies\n\n\nBefore we leave these next steps, you may be interested in understanding how to use cookies. First of all, you need to be on the domain that the cookie will be valid for:\n\n\n# Go to the correct domain\ndriver.get(\nhttp://www.example.com\n)\n\n# Now set the cookie. This one's valid for the entire domain\ncookie = {\u2018name\u2019 : \u2018foo\u2019, \u2018value\u2019 : \u2018bar\u2019}\ndriver.add_cookie(cookie)\n\n# And now output all the available cookies for the current URL\ndriver.get_cookies()", 
            "title": "Navigating"
        }, 
        {
            "location": "/navigating/index.html#navigating", 
            "text": "The first thing you\u2019ll want to do with WebDriver is navigate to a link. The normal way to do this is by calling  get  method:  driver.get( http://www.google.com )  Note  :\nWebDriver will wait until the page has fully loaded (that is, the onload event has fired) before returning control to your test or script. It\u2019s worth noting that if your page uses a lot of AJAX on load then WebDriver may not know when it has completely loaded. If you need to ensure such pages are fully loaded then you can use waits.", 
            "title": "Navigating"
        }, 
        {
            "location": "/navigating/index.html#interacting-with-the-page", 
            "text": "Just being able to go to places isn\u2019t terribly useful. What we\u2019d really like to do is to interact with the pages, or, more specifically, the HTML elements within a page. First of all, we need to find one. WebDriver offers a number of ways to find elements. For example, given an element defined as:  input type= text  name= passwd  id= passwd-id  /   you could find it using any of:  element = driver.find_element_by_id( passwd-id )\nelement = driver.find_element_by_name( passwd )\nelement = driver.find_element_by_xpath( //input[@id='passwd-id'] )  You can also look for a link by its text, but be careful! The text must be an exact match! You should also be careful when using XPATH in WebDriver. If there\u2019s more than one element that matches the query, then only the first will be returned. If nothing can be found, a  NoSuchElementException  will be raised.  Now,  you\u2019ve got an element. What can you do with it? First of all, you may want to enter some text into a text field:  element.send_keys( some text )  You can simulate pressing the arrow keys by using the \u201cKeys\u201d class:  element.send_keys(  and some , Keys.ARROW_DOWN)  It is possible to call send_keys on any element, which makes it possible to test keyboard shortcuts such as those used on GMail. A side-effect of this is that typing something into a text field won\u2019t automatically clear it. Instead, what you type will be appended to what\u2019s already there. You can easily clear the contents of a text field or textarea with the clear method:  element.clear()", 
            "title": "Interacting with the page"
        }, 
        {
            "location": "/navigating/index.html#drag-and-drop", 
            "text": "You can use drag and drop, either moving an element by a certain amount, or on to another element:  element = driver.find_element_by_name( source )\ntarget = driver.find_element_by_name( target )\n\nfrom selenium.webdriver import ActionChains\naction_chains = ActionChains(driver)\naction_chains.drag_and_drop(element, target).perform()", 
            "title": "Drag and drop"
        }, 
        {
            "location": "/navigating/index.html#moving-between-windows-and-frames", 
            "text": "It\u2019s rare for a modern web application not to have any frames or to be constrained to a single window. WebDriver supports moving between named windows using the \u201c switch_to_window \u201d method:  driver.switch_to_window( windowName )  All calls to  driver  will now be interpreted as being directed to the particular window. But how do you know the window\u2019s name? Take a look at the javascript or link that opened it:  a href= somewhere.html  target= windowName Click here to open a new window /a   Alternatively, you can pass a \u201cwindow handle\u201d to the \u201cswitch_to_window()\u201d method. Knowing this, it\u2019s possible to iterate over every open window like so:  for handle in driver.window_handles:\n    driver.switch_to_window(handle)  You can also swing from frame to frame (or into iframes):  driver.switch_to_frame( frameName )  Once we are done with working on frames, we will have to come back to the parent frame which can be done using:  driver.switch_to_default_content()", 
            "title": "Moving between windows and frames"
        }, 
        {
            "location": "/navigating/index.html#popup-dialogs", 
            "text": "Selenium WebDriver has built-in support for handling popup dialog boxes. After you\u2019ve triggered action that would open a popup, you can access the alert with the following:  alert = driver.switch_to_alert()  This will return the currently open alert object. With this object, you can now accept, dismiss, read its contents or even type into a prompt. This interface works equally well on alerts, confirms, prompts. Refer to the API documentation for more information.", 
            "title": "Popup dialogs"
        }, 
        {
            "location": "/navigating/index.html#navigation-history-and-location", 
            "text": "Earlier, we covered navigating to a page using the \u201cget\u201d command (  driver.get(\"http://www.example.com\") ) As you\u2019ve seen, WebDriver has a number of smaller, task-focused interfaces, and navigation is a useful task. To navigate to a page, you can use get method:  driver.get( http://www.example.com )  To move backward and forward in your browser\u2019s history:  driver.forward()\ndriver.back()  Please be aware that this functionality depends entirely on the underlying driver. It\u2019s just possible that something unexpected may happen when you call these methods if you\u2019re used to the behavior of one browser over another.", 
            "title": "Navigation: history and location"
        }, 
        {
            "location": "/navigating/index.html#cookies", 
            "text": "Before we leave these next steps, you may be interested in understanding how to use cookies. First of all, you need to be on the domain that the cookie will be valid for:  # Go to the correct domain\ndriver.get( http://www.example.com )\n\n# Now set the cookie. This one's valid for the entire domain\ncookie = {\u2018name\u2019 : \u2018foo\u2019, \u2018value\u2019 : \u2018bar\u2019}\ndriver.add_cookie(cookie)\n\n# And now output all the available cookies for the current URL\ndriver.get_cookies()", 
            "title": "Cookies"
        }, 
        {
            "location": "/locating_elements/index.html", 
            "text": "Locating Elements\n\n\nThere are various strategies to locate elements in a page. You can use the most appropriate one for your case. Selenium provides the following methods to locate elements in a page:\n\n\n\n\nfind_element_by_id\n\n\nfind_element_by_name\n\n\nfind_element_by_xpath\n\n\nfind_element_by_link_text\n\n\nfind_element_by_partial_link_text\n\n\nfind_element_by_tag_name\n\n\nfind_element_by_class_name\n\n\nfind_element_by_css_selector\n\n\n\n\nTo find multiple elements (these methods will return a list)\n:\n\n\n\n\nfind_elements_by_name\n\n\nfind_elements_by_xpath\n\n\nfind_elements_by_link_text\n\n\nfind_elements_by_partial_link_text\n\n\nfind_elements_by_tag_name\n\n\nfind_elements_by_class_name\n\n\nfind_elements_by_css_selector\n\n\n\n\nApart from the public methods given above, there are two private methods which might be useful with locators in page objects. These are the two private methods: find_element and find_elements.\n\n\nExample usage:\n\n\nfrom selenium.webdriver.common.by import By\n\ndriver.find_element(By.XPATH, '//button[text()=\nSome text\n]')\ndriver.find_elements(By.XPATH, '//button')\n\n\n\n\nThese are the attributes available for By class:\n\n\nID = \nid\n\nXPATH = \nxpath\n\nLINK_TEXT = \nlink text\n\nPARTIAL_LINK_TEXT = \npartial link text\n\nNAME = \nname\n\nTAG_NAME = \ntag name\n\nCLASS_NAME = \nclass name\n\nCSS_SELECTOR = \ncss selector\n\n\n\n\n\nLocating by Id\n\n\nUse this when you know id attribute of an element. With this strategy, the first element with the id attribute value matching the location will be returned. If no element has a matching id attribute, a \nNoSuchElementException\n will be raised.\n\n\nFor instance, consider this page source:\n\n\nhtml\n\n \nbody\n\n  \nform id=\nloginForm\n\n   \ninput name=\nusername\n type=\ntext\n /\n\n   \ninput name=\npassword\n type=\npassword\n /\n\n   \ninput name=\ncontinue\n type=\nsubmit\n value=\nLogin\n /\n\n  \n/form\n\n \n/body\n\n\nhtml\n\n\n\n\n\nThe form element can be located like this:\n\n\nlogin_form = driver.find_element_by_id('loginForm')\n\n\n\n\nLocating by Name\n\n\nUse this when you know name attribute of an element. With this strategy, the first element with the name attribute value matching the location will be returned. If no element has a matching name attribute, a \nNoSuchElementException\n will be raised.\n\n\nFor instance, consider this page source:\n\n\nhtml\n\n \nbody\n\n  \nform id=\nloginForm\n\n   \ninput name=\nusername\n type=\ntext\n /\n\n   \ninput name=\npassword\n type=\npassword\n /\n\n   \ninput name=\ncontinue\n type=\nsubmit\n value=\nLogin\n /\n\n   \ninput name=\ncontinue\n type=\nbutton\n value=\nClear\n /\n\n  \n/form\n\n\n/body\n\n\nhtml\n\n\n\n\n\nThe username \n password elements can be located like this:\n\n\nusername = driver.find_element_by_name('username')\npassword = driver.find_element_by_name('password')\n\n\n\n\nThis will give the \u201cLogin\u201d button as it occurs before the \u201cClear\u201d button:\n\n\ncontinue = driver.find_element_by_name('continue')\n\n\n\n\nLocating by XPath\n\n\nXPath is the language used for locating nodes in an XML document. As HTML can be an implementation of XML (XHTML), Selenium users can leverage this powerful language to target elements in their web applications. XPath extends beyond (as well as supporting) the simple methods of locating by id or name attributes, and opens up all sorts of new possibilities such as locating the third checkbox on the page.\n\n\nOne of the main reasons for using XPath is when you don\u2019t have a suitable id or name attribute for the element you wish to locate. You can use XPath to either locate the element in absolute terms (not advised), or relative to an element that does have an id or name attribute. XPath locators can also be used to specify elements via attributes other than id and name.\n\n\nAbsolute XPaths contain the location of all elements from the root (html) and as a result are likely to fail with only the slightest adjustment to the application. By finding a nearby element with an id or name attribute (ideally a parent element) you can locate your target element based on the relationship. This is much less likely to change and can make your tests more robust.\n\n\nFor instance, consider this page source:\n\n\nhtml\n\n \nbody\n\n  \nform id=\nloginForm\n\n   \ninput name=\nusername\n type=\ntext\n /\n\n   \ninput name=\npassword\n type=\npassword\n /\n\n   \ninput name=\ncontinue\n type=\nsubmit\n value=\nLogin\n /\n\n   \ninput name=\ncontinue\n type=\nbutton\n value=\nClear\n /\n\n  \n/form\n\n\n/body\n\n\nhtml\n\n\n\n\n\nThe form elements can be located like this:\n\n\nlogin_form = driver.find_element_by_xpath(\n/html/body/form[1]\n)\nlogin_form = driver.find_element_by_xpath(\n//form[1]\n)\nlogin_form = driver.find_element_by_xpath(\n//form[@id='loginForm']\n)\n\n\n\n\n\n\nAbsolute path (would break if the HTML was changed only slightly)\n\n\nFirst form element in the HTML\n\n\nThe form element with attribute named id and the value loginForm\n\n\n\n\nThe username element can be located like this:\n\n\nusername = driver.find_element_by_xpath(\n//form[input/@name='username']\n)\nusername = driver.find_element_by_xpath(\n//form[@id='loginForm']/input[1]\n)\nusername = driver.find_element_by_xpath(\n//input[@name='username']\n)\n\n\n\n\n\n\nFirst form element with an input child element with attribute named name and the value username\n\n\nFirst input child element of the form element with attribute named id and the value loginForm\n\n\nFirst input element with attribute named \u2018name\u2019 and the value username\n\n\n\n\nThe \u201cClear\u201d button element can be located like this:\n\n\nclear_button = driver.find_element_by_xpath(\n//input[@name='continue'][@type='button']\n)\nclear_button = driver.find_element_by_xpath(\n//form[@id='loginForm']/input[4]\n)\n\n\n\n\n\n\nInput with attribute named name and the value continue and attribute named type and the value button\n\n\nFourth input child element of the form element with attribute named id and value loginForm\n\n\n\n\nLocating Hyperlinks by Link Text\n\n\nUse this when you know link text used within an anchor tag. With this strategy, the first element with the link text value matching the location will be returned. If no element has a matching link text attribute, a \nNoSuchElementException\n will be raised.\n\n\nFor instance, consider this page source:\n\n\nhtml\n\n \nbody\n\n  \np\nAre you sure you want to do this?\n/p\n\n  \na href=\ncontinue.html\nContinue\n/a\n\n  \na href=\ncancel.html\nCancel\n/a\n\n\n/body\n\n\nhtml\n\n\n\n\n\nThe continue.html link can be located like this:\n\n\ncontinue_link = driver.find_element_by_link_text('Continue')\ncontinue_link = driver.find_element_by_partial_link_text('Conti')\n\n\n\n\nLocating Elements by Tag Name\n\n\nUse this when you want to locate an element by tag name. With this strategy, the first element with the given tag name will be returned. If no element has a matching tag name, a \nNoSuchElementException\n will be raised.\n\n\nFor instance, consider this page source:\n\n\nhtml\n\n \nbody\n\n  \nh1\nWelcome\n/h1\n\n  \np\nSite content goes here.\n/p\n\n\n/body\n\n\nhtml\n\n\n\n\n\nThe heading (h1) element can be located like this:\n\n\nheading1 = driver.find_element_by_tag_name('h1')\n\n\n\n\nLocating Elements by Class Name\n\n\nUse this when you want to locate an element by class attribute name. With this strategy, the first element with the matching class attribute name will be returned. If no element has a matching class attribute name, a \nNoSuchElementException\n will be raised.\n\n\nFor instance, consider this page source:\n\n\nhtml\n\n \nbody\n\n  \np class=\ncontent\nSite content goes here.\n/p\n\n\n/body\n\n\nhtml\n\n\n\n\n\nThe \u201cp\u201d element can be located like this:\n\n\ncontent = driver.find_element_by_class_name('content')\n\n\n\n\nLocating Elements by CSS Selectors\n\n\nUse this when you want to locate an element by CSS selector syntax. With this strategy, the first element with the matching CSS selector will be returned. If no element has a matching CSS selector, a \nNoSuchElementException\n will be raised.\n\n\nFor instance, consider this page source:\n\n\nhtml\n\n \nbody\n\n  \np class=\ncontent\nSite content goes here.\n/p\n\n\n/body\n\n\nhtml\n\n\n\n\n\nThe \u201cp\u201d element can be located like this:\n\n\ncontent = driver.find_element_by_css_selector('p.content')", 
            "title": "Locating Elements"
        }, 
        {
            "location": "/locating_elements/index.html#locating-elements", 
            "text": "There are various strategies to locate elements in a page. You can use the most appropriate one for your case. Selenium provides the following methods to locate elements in a page:   find_element_by_id  find_element_by_name  find_element_by_xpath  find_element_by_link_text  find_element_by_partial_link_text  find_element_by_tag_name  find_element_by_class_name  find_element_by_css_selector   To find multiple elements (these methods will return a list) :   find_elements_by_name  find_elements_by_xpath  find_elements_by_link_text  find_elements_by_partial_link_text  find_elements_by_tag_name  find_elements_by_class_name  find_elements_by_css_selector   Apart from the public methods given above, there are two private methods which might be useful with locators in page objects. These are the two private methods: find_element and find_elements.  Example usage:  from selenium.webdriver.common.by import By\n\ndriver.find_element(By.XPATH, '//button[text()= Some text ]')\ndriver.find_elements(By.XPATH, '//button')  These are the attributes available for By class:  ID =  id \nXPATH =  xpath \nLINK_TEXT =  link text \nPARTIAL_LINK_TEXT =  partial link text \nNAME =  name \nTAG_NAME =  tag name \nCLASS_NAME =  class name \nCSS_SELECTOR =  css selector", 
            "title": "Locating Elements"
        }, 
        {
            "location": "/locating_elements/index.html#locating-by-id", 
            "text": "Use this when you know id attribute of an element. With this strategy, the first element with the id attribute value matching the location will be returned. If no element has a matching id attribute, a  NoSuchElementException  will be raised.  For instance, consider this page source:  html \n  body \n   form id= loginForm \n    input name= username  type= text  / \n    input name= password  type= password  / \n    input name= continue  type= submit  value= Login  / \n   /form \n  /body  html   The form element can be located like this:  login_form = driver.find_element_by_id('loginForm')", 
            "title": "Locating by Id"
        }, 
        {
            "location": "/locating_elements/index.html#locating-by-name", 
            "text": "Use this when you know name attribute of an element. With this strategy, the first element with the name attribute value matching the location will be returned. If no element has a matching name attribute, a  NoSuchElementException  will be raised.  For instance, consider this page source:  html \n  body \n   form id= loginForm \n    input name= username  type= text  / \n    input name= password  type= password  / \n    input name= continue  type= submit  value= Login  / \n    input name= continue  type= button  value= Clear  / \n   /form  /body  html   The username   password elements can be located like this:  username = driver.find_element_by_name('username')\npassword = driver.find_element_by_name('password')  This will give the \u201cLogin\u201d button as it occurs before the \u201cClear\u201d button:  continue = driver.find_element_by_name('continue')", 
            "title": "Locating by Name"
        }, 
        {
            "location": "/locating_elements/index.html#locating-by-xpath", 
            "text": "XPath is the language used for locating nodes in an XML document. As HTML can be an implementation of XML (XHTML), Selenium users can leverage this powerful language to target elements in their web applications. XPath extends beyond (as well as supporting) the simple methods of locating by id or name attributes, and opens up all sorts of new possibilities such as locating the third checkbox on the page.  One of the main reasons for using XPath is when you don\u2019t have a suitable id or name attribute for the element you wish to locate. You can use XPath to either locate the element in absolute terms (not advised), or relative to an element that does have an id or name attribute. XPath locators can also be used to specify elements via attributes other than id and name.  Absolute XPaths contain the location of all elements from the root (html) and as a result are likely to fail with only the slightest adjustment to the application. By finding a nearby element with an id or name attribute (ideally a parent element) you can locate your target element based on the relationship. This is much less likely to change and can make your tests more robust.  For instance, consider this page source:  html \n  body \n   form id= loginForm \n    input name= username  type= text  / \n    input name= password  type= password  / \n    input name= continue  type= submit  value= Login  / \n    input name= continue  type= button  value= Clear  / \n   /form  /body  html   The form elements can be located like this:  login_form = driver.find_element_by_xpath( /html/body/form[1] )\nlogin_form = driver.find_element_by_xpath( //form[1] )\nlogin_form = driver.find_element_by_xpath( //form[@id='loginForm'] )   Absolute path (would break if the HTML was changed only slightly)  First form element in the HTML  The form element with attribute named id and the value loginForm   The username element can be located like this:  username = driver.find_element_by_xpath( //form[input/@name='username'] )\nusername = driver.find_element_by_xpath( //form[@id='loginForm']/input[1] )\nusername = driver.find_element_by_xpath( //input[@name='username'] )   First form element with an input child element with attribute named name and the value username  First input child element of the form element with attribute named id and the value loginForm  First input element with attribute named \u2018name\u2019 and the value username   The \u201cClear\u201d button element can be located like this:  clear_button = driver.find_element_by_xpath( //input[@name='continue'][@type='button'] )\nclear_button = driver.find_element_by_xpath( //form[@id='loginForm']/input[4] )   Input with attribute named name and the value continue and attribute named type and the value button  Fourth input child element of the form element with attribute named id and value loginForm", 
            "title": "Locating by XPath"
        }, 
        {
            "location": "/locating_elements/index.html#locating-hyperlinks-by-link-text", 
            "text": "Use this when you know link text used within an anchor tag. With this strategy, the first element with the link text value matching the location will be returned. If no element has a matching link text attribute, a  NoSuchElementException  will be raised.  For instance, consider this page source:  html \n  body \n   p Are you sure you want to do this? /p \n   a href= continue.html Continue /a \n   a href= cancel.html Cancel /a  /body  html   The continue.html link can be located like this:  continue_link = driver.find_element_by_link_text('Continue')\ncontinue_link = driver.find_element_by_partial_link_text('Conti')", 
            "title": "Locating Hyperlinks by Link Text"
        }, 
        {
            "location": "/locating_elements/index.html#locating-elements-by-tag-name", 
            "text": "Use this when you want to locate an element by tag name. With this strategy, the first element with the given tag name will be returned. If no element has a matching tag name, a  NoSuchElementException  will be raised.  For instance, consider this page source:  html \n  body \n   h1 Welcome /h1 \n   p Site content goes here. /p  /body  html   The heading (h1) element can be located like this:  heading1 = driver.find_element_by_tag_name('h1')", 
            "title": "Locating Elements by Tag Name"
        }, 
        {
            "location": "/locating_elements/index.html#locating-elements-by-class-name", 
            "text": "Use this when you want to locate an element by class attribute name. With this strategy, the first element with the matching class attribute name will be returned. If no element has a matching class attribute name, a  NoSuchElementException  will be raised.  For instance, consider this page source:  html \n  body \n   p class= content Site content goes here. /p  /body  html   The \u201cp\u201d element can be located like this:  content = driver.find_element_by_class_name('content')", 
            "title": "Locating Elements by Class Name"
        }, 
        {
            "location": "/locating_elements/index.html#locating-elements-by-css-selectors", 
            "text": "Use this when you want to locate an element by CSS selector syntax. With this strategy, the first element with the matching CSS selector will be returned. If no element has a matching CSS selector, a  NoSuchElementException  will be raised.  For instance, consider this page source:  html \n  body \n   p class= content Site content goes here. /p  /body  html   The \u201cp\u201d element can be located like this:  content = driver.find_element_by_css_selector('p.content')", 
            "title": "Locating Elements by CSS Selectors"
        }
    ]
}